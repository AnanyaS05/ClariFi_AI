# Step 2: Designing Prompting Techniques
# We will build ReAct prompting, which extends that idea by mixing the model's written thoughts with actions.

# Recall that the agent model follows a loop (Thought → Action → Observation) where it first using chain-of-thought prompting about what to do, then takes an action, reads the result, and repeats until it is ready to answer.
# We will define a prompting format that explicitly concatnate Thought, Action, Observation into a prompt:

# We define:
#   1) A method for parsing Action lines
#   2) A small argument parser for the tools defined in the last step, such as parsing key="value", key=123, key=4.5, key=true/false
#   3) Helpers to format the agent’s history and build the next prompt
from typing import Any, Dict, List, Optional, Tuple
import ast
import re
import textwrap
import csv, io


# The prompt for a language model in a ReAct framework is in the following format
#     "User prompt: 'Who painted The Starry Night and where was it painted?' "
#     "Thought: I should search for key facts about the painting"
#     "Action: search[query="starry night", k=3]"
#     "Observation: {"results": [{"title": "The Starry Night"}]}"
#
#     The thought and action will be generated by a language model
#     The observation would be the returned results from the search method we defined above
#     We will implement to interleave the language model with external tools (e.g., the search method)


# ======= Helper functions =======
def convert_value(raw: str) -> Any:
    """
    Convert a raw string token into a Python type:
      - quoted strings -> str
      - numbers -> int or float
      - true/false -> bool
      - otherwise -> original string (stripped)
    Uses ast.literal_eval for safety (no code execution).
    """
    raw = raw.strip()
    # Normalize JSON-like booleans
    if raw.lower() == "true":  return True
    if raw.lower() == "false": return False
    try:
        # Handles "..." / '...' / 123 / 4.5
        return ast.literal_eval(raw)
    except Exception:
        # Fallback: unquoted, non-numeric tokens
        return raw.strip('"').strip("'")

def split_args(argstr: str) -> Dict[str, Any]:
    """
    This function splits the string such as 'k=3, query="starry night"' into a dictionary {'k':3, 'query':'starry night'},
    Note: relies on double quotes to protect commas inside strings.
    """
    args: Dict[str, Any] = {}
    row = next(csv.reader(io.StringIO(argstr), delimiter=",", skipinitialspace=True, quotechar='"'), [])
    for field in row:
        field = field.strip()
        if not field:
            continue
        if "=" in field:
            key, val = field.split("=", 1)
            args[key.strip()] = convert_value(val)
        else:
            # bare flag -> True
            args[field] = True
    return args
# ====== Helper functions ======

# We will write a parser that converts a string of actions to arguments
#       For example, a languge model would ouptut actions in the following form:
#       'Action: search[query="starry night", k=3]'
#       'Action: finish[answer="Vincent van Gogh, at Saint-Rémy-de-Provence."]'
#
#       We will need a function to parse them into a function call to external tools
#
#       Let's implement the key function for this task
def parse_action(line: str) -> Optional[Tuple[str, Dict[str, Any]]]:
    """
    Parse lines like:
      Action: search[query="van gogh starry night", k=3]
      Action: finish[answer="Vincent van Gogh."]
    Returns (action_name, args_dict) or None on invalid input.
    """
    # Validate prefix
    if not isinstance(line, str):
        return None
    line = line.strip()
    if not line.lower().startswith("action:"):
        return None

    # Extract the part after 'Action:'
    rest = line[len("Action:"):].strip()

    # Try to match: name[argstr]
    m = re.match(r"^([A-Za-z_][A-Za-z0-9_]*)\s*\[(.*)\]$", rest, flags=re.DOTALL)
    if not m:
        # Allow a bare action name without brackets: e.g., 'Action: finish'
        m2 = re.match(r"^([A-Za-z_][A-Za-z0-9_]*)$", rest)
        if m2:
            name = m2.group(1)
            args = {}
            return name, args
        return None

    name = m.group(1)
    argstr = m.group(2).strip()

    # If empty arg string, return empty args
    if argstr == "":
        return name, {}

    try:
        args = split_args(argstr)
    except Exception:
        return None

    return name, args



# 2. We write a function that turn past steps into a readable history block for the prompt
def format_history(trajectory: List[Dict[str, str]]) -> str:
    """
    Each step in trajectory should have keys: 'thought', 'action', 'observation'.
    We render them in the canonical ReAct order for the next prompt.
    """
    lines: List[str] = []
    for step in trajectory:
        lines.append(f"Thought: {step['thought']}")
        lines.append(f"Action: {step['action']}")
        lines.append(f"Observation: {step['observation']}")
    return "\n".join(lines)


# 3. We will build the prompt shown to the model for the next step
SYSTEM_PREAMBLE = textwrap.dedent("""\
    You are a helpful ReAct agent. You may use tools to answer factual questions.

    Available tools:
    - search[query="<text>", k=<int>]  # searches a small encyclopedia and returns top-k results
    To finish, use: finish[answer="<final answer>"]

    Follow the exact step format:
    Thought: <your reasoning>
    Action: <one of the tool calls above, or finish[...]>
""").strip()

def make_prompt(user_query: str, trajectory: List[Dict[str, str]]) -> str:
    """
    Construct the model prompt by concatenating:
      (1) a clear system preamble with the tool contract,
      (2) the user question,
      (3) the formatted history so far,
      (4) a cue to produce the next Thought.
    """
    history_block = format_history(trajectory)
    return (
        f"{SYSTEM_PREAMBLE}\n\n"
        f"User Question: {user_query}\n\n"
        f"{history_block}\n"
        f"Next step:\n"
        f"Thought:"
    )